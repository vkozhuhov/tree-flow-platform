### Второе задание — официальное ТЗ «Три сервиса»

### ⚓ Сервис 1 — Gateway

Основная задача:
принимать заявки → распределять по каналам → отправлять в сервисы 2 и 3.

Требования
1. Три канала (Channel<T>):

- приоритетный

- основной

- вторичный

2. Распределение нагрузки по весу заявки

Например:

- 80 → приоритетный

- 40–80 → основной

- < 40 → вторичный

(правила задаёт наставник, стажёр менять не должен (делай по усмотрению))

3. Принцип ТМО

- приоритетный канал должен обслуживаться первым

- но нельзя игнорировать остальные (никаких starvation)

4. Обработка

- имитация работы: 1–2 секунды

дальше:

- по Kafka → в сервис 3

- по gRPC → в сервис 2

5. API:

POST /application
Принимает заявку, рассчитывает вес, кладёт в канал.
Ответ: 202 Accepted + ID.

---

### ⚓ Сервис 2 — File Storage Service

Эмуляция S3 и работа с файлами.

Методы:
1. healthCheck

Просто проверяет, что сервис жив.

2. writeToTemporalStorage

Принимает файлы по API, сохраняет во временное хранилище.

3. moveToPermanentStorage

Если заявка успешно принята:

- переносит файл в постоянное хранилище

- генерирует и возвращает PreSignedUrl ссылку

4. PreSignedUrl

Восстановление PreSignedUrl ссылки, если её потеряли.

Взаимодействие с Gateway:

- Gateway сначала отправляет заявку по gRPC

- затем отправляет файл

- сервис 2 переносит файл и отдаёт PreSignedUrl

Все конфигурации Kafka/S3 — через Expert.Secrets.

---

## ⚓ Сервис 3 — Application Processor

Обрабатывает заявки, валидирует, сохраняет.

Требования:
1. Kafka consumer

Слушает заявки от gateway.

2. Параллельная обработка

Каждая заявка — отдельная Task.

3. Валидация

При ошибке:
генерирует сообщение → отправляет обратно по Kafka в gateway.

4. Сохранение

Используем:

- PostgreSQL, драйвер Npgsql

- без EF

5. Учёт статистики

Вести счётчик обработанных заявок:

- in-memory

- периодически сохранять в файл или БД

6. Ответ в Kafka

После обработки отправляет статус обратно в gateway.

Конфигурации Kafka/Postgres — через Expert.Secrets.

---